{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64580929",
   "metadata": {},
   "source": [
    "# Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f0b3a",
   "metadata": {},
   "source": [
    "Previously, we learned how to write our own functions that could be called multiple times. It is possible to call functions that other people have written as well! We do this by importing files that define the various functions we could use. Two of the most important Libraries (collection of files with pre-defined functions) are **numpy** and **pandas**. \n",
    "\n",
    "**numpy**, short for **num**erical **py**thon, specializes in arrays and is heavily used for its RANDOM functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e83d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# randint(VALUE) generates a random integer between 0 and VALUE (not including VALUE)\n",
    "x = numpy.random.randint(100)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a575f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we JUST import the random functions from numpy and ignore the rest of the library\n",
    "# When we do this, we don't need to include the library name\n",
    "from numpy import random\n",
    "\n",
    "x = random.randint(100)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05a3ba",
   "metadata": {},
   "source": [
    "**pandas** is short for **pan**el **da**ta and is primarily used for data analysis. We will heavily rely on pandas to manipulate data. pandas requires numpy to be imported, so you will commonly see the two imported at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76062ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternaively, you can cut down on your typing by providing an alias for the library names\n",
    "# Pandas own documentation uses the aliases below. \n",
    "# See https://pandas.pydata.org/docs/user_guide/10min.html for an example\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce0742",
   "metadata": {},
   "source": [
    "# Importing Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846aab19",
   "metadata": {},
   "source": [
    "A **file type** tells you how data is saved. Different file types specialize in saving data in certain ways. A great example is docx vs xlsx files. docx files are excellent at displaying large portions of text and images in a horizontal or vertical format. xlsx files are excellent at saving large portions of data in neat rows and columns so that you can perform functions on specific portions of the data. \n",
    "\n",
    "For Python to read a particular file type, you will need specialized functions that extract the information in ways we understand. This is a great example of where libraries can be incredibly useful! Here is a list of file types and the associated library you would want to install to work with the files. *run \"pip install ____\" in a terminal or command prompt to install the file\n",
    "\n",
    "- **.docx**: python-docx\n",
    "- **.csv**: pandas\n",
    "- **.xlsx**: pandas\n",
    "- **.pdf**: pymupdf\n",
    "\n",
    "In our course, we will focus solely on csv and xlsx files as these are the most common Data Science file types you will need to manipulate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683eb017",
   "metadata": {},
   "source": [
    "# Import xlsx using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09cb9b",
   "metadata": {},
   "source": [
    "Let's get some government data to learn how to use pandas. \n",
    "\n",
    "1. From https://www.bls.gov/oes/tables.htm, download the most recent \"All data\" XLSX file. This will download a zip file to your Downloads folder. \n",
    "2. Unzip the folder. \n",
    "3. Move the file named \"all_data_M_20XX.xlsx\" (XX will be the last two digits of the year you chose) to the folder where you run your jupyter notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "# For this example, I downloaded May 2022 data\n",
    "# This will take 1-2 minutes as there are 400,000+ rows of data!\n",
    "dataframe = pandas.read_excel(\"all_data_M_2022.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head() prints the first 5 rows of the dataframe\n",
    "# Very useful for reading the column names and seeing the first few rows\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f3c65",
   "metadata": {},
   "source": [
    "### Some notes:\n",
    "**columns** are bolded across the top. Be sure to find descriptions of each column name when you download databases. For example, you can find the description of all OCC_CODE and OCC_TITLE here: https://www.bls.gov/oes/current/oes_stru.htm\n",
    "\n",
    "**NaN** means Not a Number. This commonly happens when the cell is left blank in an xlsx document. \n",
    "\n",
    "The size of the dataframe is in the bottom-left corner. Since we only printed the head, it is showing 5 rows. Try removing the .head() and see how many rows the actual dataframe has."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea2e9c",
   "metadata": {},
   "source": [
    "## Venn Diagram of Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e881e36",
   "metadata": {},
   "source": [
    "StackOverflow has an excellent discussion of different types of merging WITH VISUALS: https://stackoverflow.com/questions/38549/what-is-the-difference-between-inner-join-and-outer-join\n",
    "\n",
    "Key Visual Summary: https://i.stack.imgur.com/hMKKt.jpg\n",
    "- **Concatenate** - Return all rows with NaN for missing data\n",
    "- **Inner Merge** - Return rows with column matches in both dataframes\n",
    "- **Outer Merge** - Return rows with column matches in either dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df83fd9",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2634a",
   "metadata": {},
   "source": [
    "The idea to concatenating is to take the two dataframes and stack them on one another. Any missing data (columns defined in one dataframe and not in the other) are treated as NaN. **There is no attempt to match and exclude data.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d515f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pandas.DataFrame({'col_1': [1, 2], 'col_2': [3, 4]})\n",
    "df_2 = pandas.DataFrame({'col_1': [11, 12], 'col_3': [13, 14]})\n",
    "concat_df = pandas.concat([df_1, df_2])\n",
    "\n",
    "concat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2466ad",
   "metadata": {},
   "source": [
    "Notice that some values were changed from integers to float. We will deal with that in a future lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79a22ee",
   "metadata": {},
   "source": [
    "## Inner Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1533d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pandas.DataFrame({'col_1': [1, 2], 'col_2': [3, 4], 'col_3': [13, 14]})\n",
    "df_2 = pandas.DataFrame({'col_1': [1, 2], 'col_3': [3, 24]})\n",
    "inner_merge_df = pandas.merge(df_1, df_2, how=\"inner\")\n",
    "\n",
    "inner_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba507443",
   "metadata": {},
   "source": [
    "Since there are no perfectly matched rows, the output is empty. But what if we wanted to check for partial matches? We can define the columns we want to merge on with **on=[]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pandas.DataFrame({'col_1': [1, 2], 'col_2': [3, 4], 'col_3': [13, 14]})\n",
    "df_2 = pandas.DataFrame({'col_1': [1, 12], 'col_2': [100, 200], 'col_3': [13, 14]})\n",
    "inner_merge_df = pandas.merge(df_1, df_2, how=\"inner\", on=['col_1', 'col_3'])\n",
    "# Since the first row has col_1 = 1 for both dataframes, they are merged\n",
    "\n",
    "inner_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105ec2a",
   "metadata": {},
   "source": [
    "This is a useful trick when looking for partial matches. Notice we had matches for col_1 and col_3? We did an inner merge and the conflicts for df_1 and df_2 are saved as col_2_x and col_2_y. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c0d0a",
   "metadata": {},
   "source": [
    "## Outer Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pandas.DataFrame({'col_1': [1, 2], 'col_2': [3, 4], 'col_3': [13, 14]})\n",
    "df_2 = pandas.DataFrame({'col_1': [1, 12], 'col_2': [100, 200], 'col_3': [13, 14]})\n",
    "outer_merge_df = pandas.merge(df_1, df_2, how=\"outer\", on=['col_1'])\n",
    "\n",
    "outer_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2b76a",
   "metadata": {},
   "source": [
    "Notice that we defined an outer merge on col_1. This means our match of col_1 = 1 was combined, with the conflicting values of the other columns listed. The other two rows are included since they have values defined for col_1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24eb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pandas.DataFrame({'col_1': [1, 2], 'col_2': [3, 4], 'col_3': [13, 14]})\n",
    "df_2 = pandas.DataFrame({'col_1': [1, 12], 'col_3': [13, 14]})\n",
    "outer_merge_df = pandas.merge(df_1, df_2, how=\"outer\")\n",
    "\n",
    "outer_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408a886",
   "metadata": {},
   "source": [
    "Notice how row 1 of df_2 is not included since it matches everywhere it is defined with row 1 of df_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pandas.DataFrame({'col_1': [1, 2], 'col_2': [3, 4]})\n",
    "df_2 = pandas.DataFrame({'col_1': [11, 12], 'col_3': [13, 14]})\n",
    "outer_merge_df = pandas.merge(df_1, df_2, how=\"outer\")\n",
    "\n",
    "outer_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402c2dc8",
   "metadata": {},
   "source": [
    "When there are no matching rows, an outer merge will look like a concatenate. **The main difference here is outer merge TRIES to combine copies while concatenate does not!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878e0be",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "If you looked at the key visual summary, you'll see there are more ways to combine data than concatenate, inner merge, and outer merge. However, these will be the three most common ways to merge that you will use in the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
